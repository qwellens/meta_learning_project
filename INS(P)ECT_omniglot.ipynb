{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import copy\n",
    "from torch.autograd import Variable as V\n",
    "import glob\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our tasks where we train on K shots of N characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniTask:\n",
    "    def __init__(self, K, N, noise_percent):\n",
    "        # K, N as in N-way K-shot learning\n",
    "        self.K = K\n",
    "        self.N = N \n",
    "        self.noise_percent = noise_percent\n",
    "        self.mini_train = None\n",
    "        self.mini_test = None\n",
    "        self.image_dir = \"omniglot_dataset/images_background/*/*\"\n",
    "        self.trainTransform  = transforms.Compose([transforms.Grayscale(num_output_channels=1),transforms.ToTensor()]) \n",
    "        self.mini_batch_size = 5\n",
    "        \n",
    "    def mini_train_set(self):\n",
    "        if self.mini_train is None:\n",
    "            #choose N tasks\n",
    "            characters = random.sample(glob.glob(self.image_dir), self.N)\n",
    "            \n",
    "            train_set = []\n",
    "            #choose K examples per task:\n",
    "            for i,char in enumerate(characters):\n",
    "                k_shots = random.sample(glob.glob(char+\"/*\"), self.K)\n",
    "                train_set.extend([(self.trainTransform(Image.open(shot).convert('RGB')), i) for shot in k_shots])\n",
    "            self.mini_train = random.sample(train_set, len(train_set))\n",
    "            \n",
    "        return self.mini_train\n",
    "    \n",
    "    def batched_mini_train_set(self):\n",
    "        train_set = self.mini_train_set()\n",
    "        shuffled = random.sample(train_set, len(train_set))\n",
    "        \n",
    "        batched = []\n",
    "        current_xes = []\n",
    "        current_yes = []\n",
    "        for i in range(len(shuffled)):\n",
    "            if i%self.mini_batch_size==0 and i > 0:\n",
    "                print(len(current_xes))\n",
    "                batched.append((torch.stack(current_xes), torch.Tensor(current_yes)))\n",
    "                current_xes = []\n",
    "                current_yes = []\n",
    "            current_xes.append(shuffled[i][0])\n",
    "            current_xes.append(shuffled[i][1])\n",
    "\n",
    "        return batched   \n",
    "    \n",
    "    def mini_test_set(self):\n",
    "        pass\n",
    "        #TODO: FIGURE OUT HOW MAML DOES THIS\n",
    "    \n",
    "    def eval_set(self, size=50):\n",
    "        pass\n",
    "        #TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 1 in argument 0, but got int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-961a1fa304d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOmniTask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatched_mini_train_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-56-aae6e7189db5>\u001b[0m in \u001b[0;36mbatched_mini_train_set\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_xes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0mbatched\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_xes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_yes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                 \u001b[0mcurrent_xes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mcurrent_yes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected Tensor as element 1 in argument 0, but got int"
     ]
    }
   ],
   "source": [
    "trial = OmniTask(5,5,0)\n",
    "train_set = trial.batched_mini_train_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, size=50000, K = 5, N = 5, noise_percent=0):\n",
    "        self.size = size\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.noise_percent = noise_percent\n",
    "        self.tasks = None \n",
    "        \n",
    "    def generate_set(self):\n",
    "        self.tasks = tasks = [OmniTask(self.K, self.N, self.noise_percent) for _ in range(self.size)]\n",
    "        return tasks\n",
    "    \n",
    "    def shuffled_set(self):\n",
    "        if self.tasks is None:\n",
    "            self.generate_set()\n",
    "        return random.sample(self.tasks, len(self.tasks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # 28 x 28 - 1\n",
    "            nn.Conv2d(1, 64, 3, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 14 x 14 - 64\n",
    "            nn.Conv2d(64, 64, 3, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 7 x 7 - 64\n",
    "            nn.Conv2d(64, 64, 3, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 4 x 4 - 64\n",
    "            nn.Conv2d(64, 64, 3, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 2 x 2 - 64\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            # 2 x 2 x 64 = 256\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.LogSoftmax(1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, 1, 28, 28)\n",
    "        out = self.conv(out)\n",
    "        out = out.view(len(out), -1) # should be equivalent to out.view(-1, 256)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def predict(self, prob):\n",
    "        __, argmax = prob.max(1)\n",
    "        return argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reptile Meta-Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLearner():\n",
    "    def __init__(self, higher_order=False, lr_inner=0.01, lr_outer=0.001, sgd_steps_inner=10):\n",
    "        self.lr_inner = lr_inner\n",
    "        self.lr_outer = lr_outer\n",
    "        self.sgd_steps_inner = sgd_steps_inner\n",
    "        self.higher_order = higher_order\n",
    "        \n",
    "    def inner_train(self, model, task, optimizer):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = task.mini_train_set()\n",
    "        predicted = model(x)\n",
    "        loss = F.mse_loss(predicted, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    def init_grad(self, model):\n",
    "        for param in model.parameters():\n",
    "            param.grad = torch.zeros_like(param)\n",
    "        \n",
    "class Reptile(MetaLearner):\n",
    "    def __init__(self, lr_inner=0.01, lr_outer=0.001, sgd_steps_inner=10):\n",
    "        super().__init__(False, lr_inner, lr_outer, sgd_steps_inner)\n",
    "        \n",
    "    def compute_store_gradients(self, target, current):\n",
    "        current_weights = dict(current.named_parameters())\n",
    "        target_weights = dict(target.named_parameters())\n",
    "        gradients = {name: (current_weights[name].data - target_weights[name].data) / (self.sgd_steps_inner * self.lr_inner) for name in target_weights}\n",
    "\n",
    "        for name in current_weights:\n",
    "            current_weights[name].grad.data = gradients[name]\n",
    "\n",
    "    def train(self, model, train_data):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.lr_outer)\n",
    "        self.init_grad(model)\n",
    "\n",
    "        for i, task in enumerate(train_data.shuffled_set()):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inner_model = copy.deepcopy(model)\n",
    "            inner_optim = torch.optim.SGD(inner_model.parameters(), lr=self.lr_inner)\n",
    "\n",
    "            for _ in range(self.sgd_steps_inner):\n",
    "                self.inner_train(inner_model, task, inner_optim)\n",
    "\n",
    "            self.compute_store_gradients(inner_model, model)\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 5000 == 0:\n",
    "                print(\"iteration:\", i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
